on: [push, pull_request]

name: GNU findutils compatibility tests

jobs:
  gnu-tests:
    name: Run GNU findutils tests
    runs-on: ubuntu-latest
    steps:
    - name: Checkout findutils
      uses: actions/checkout@v2
      with:
        path: findutils
    - name: Checkout GNU findutils
      uses: actions/checkout@v2
      with:
        repository: gnu-mirror-unofficial/findutils
        path: findutils.gnu
        ref: 5768a03ddfb5e18b1682e339d6cdd24ff721c510
        submodules: true
    - uses: actions-rs/toolchain@v1
      with:
        profile: minimal
        toolchain: stable
        override: true
    - name: Install dependencies
      shell: bash
      run: |
        # Enable sources & install dependencies
        sudo find /etc/apt/sources.list* -type f -exec sed -i 'p; s/^deb /deb-src /' '{}' +
        sudo apt-get update
        sudo apt-get build-dep findutils
    - name: Run GNU tests
      shell: bash
      run: |
        cd findutils
        bash util/build-gnu.sh ||:
    - name: Extract testing info
      shell: bash
      run: |
    - uses: actions/upload-artifact@v2
      with:
        name: gnu-test-report
        path: |
          findutils.gnu/find/testsuite/*.log
          findutils.gnu/xargs/testsuite/*.log
          findutils.gnu/tests/**/*.log
    - uses: actions/upload-artifact@v2
      with:
        name: gnu-result
        path: gnu-result.json
    - name: Download the result
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: compat.yml
        workflow_conclusion: completed
        name: gnu-result
        repo: uutils/findutils
        branch: main
        path: dl
    - name: Download the log
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: compat.yml
        workflow_conclusion: completed
        name: gnu-test-report
        repo: uutils/findutils
        branch: main
        path: dl
    - name: Compare failing tests against master
      shell: bash
      run: |
        mkdir -p ./logs
        cp findutils.gnu/{tests,{find,xargs}/testsuite}/*.log ./logs
        ./findutils/util/diff-gnu.sh dl logs
    - name: Compare against main results
      shell: bash
      run: |
        mv dl/gnu-result.json latest-gnu-result.json
        python findutils/util/compare_gnu_result.py

  bfs-tests:
    name: Run BFS tests
    runs-on: ubuntu-latest
    steps:
    - name: Checkout findutils
      uses: actions/checkout@v2
      with:
        path: findutils
    - name: Checkout BFS
      uses: actions/checkout@v2
      with:
        repository: tavianator/bfs
        path: bfs
        ref: '2.3.1'
    - uses: actions-rs/toolchain@v1
      with:
        profile: minimal
        toolchain: stable
        override: true
    - name: Install dependencies
      shell: bash
      run: |
        # Enable sources & install dependencies
        sudo find /etc/apt/sources.list* -type f -exec sed -i 'p; s/^deb /deb-src /' '{}' +
        sudo apt-get update
        sudo apt-get build-dep bfs
    - name: Run BFS tests
      shell: bash
      run: |
        cd findutils
        bash util/build-bfs.sh ||:
    - name: Extract testing info
      shell: bash
      run: |
        LOG_FILE=bfs/tests.log
        if test -f "$LOG_FILE"; then
          PASS=$(sed -n "s/^tests passed: \(.*\)/\1/p" "$LOG_FILE"|head -n1)
          FAIL=$(sed -n "s/^tests failed: \(.*\)/\1/p" "$LOG_FILE"|head -n1)
          TOTAL=$(($PASS + $FAIL))
          if [[ "$TOTAL" -eq 0 || "$TOTAL" -eq 1 ]]; then
              echo "Error in the execution, failing early"
              exit 1
          fi
          output="BFS tests summary = TOTAL: $TOTAL / PASS: $PASS / FAIL: $FAIL"
          echo "${output}"
          if [[ "$FAIL" -gt 0 || "$ERROR" -gt 0 ]]; then echo "::warning ::${output}" ; fi
          jq -n \
                --arg date "$(date --rfc-email)" \
                --arg sha "$GITHUB_SHA" \
                --arg total "$TOTAL" \
                --arg pass "$PASS" \
                --arg fail "$FAIL" \
                '{($date): { sha: $sha, total: $total, pass: $pass, fail: $fail, }}' > bfs-result.json
        else
          echo "::error ::Failed to get summary of test results"
        fi
    - uses: actions/upload-artifact@v2
      with:
        name: bfs-test-report
        path: bfs/tests.log
    - uses: actions/upload-artifact@v2
      with:
        name: bfs-result
        path: bfs-result.json
    - name: Download the result
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: compat.yml
        workflow_conclusion: completed
        name: bfs-result
        repo: uutils/findutils
        branch: main
        path: dl
    - name: Download the log
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: compat.yml
        workflow_conclusion: completed
        name: bfs-test-report
        repo: uutils/findutils
        branch: main
        path: dl
    - name: Compare failing tests against main
      shell: bash
      run: |
        OLD_FAILING=$(sed -n "s/^\([[:print:]]\+\) failed\!/\1/p" dl/tests.log | sort)
        NEW_FAILING=$(sed -n "s/^\([[:print:]]\+\) failed\!/\1/p" bfs/tests.log | sort)
        for LINE in $OLD_FAILING; do
          if ! grep -Fxq $LINE<<<"$NEW_FAILING"; then
            echo "::warning ::Congrats! The bfs test $LINE is now passing!"
          fi
        done
        for LINE in $NEW_FAILING; do
          if ! grep -Fxq $LINE<<<"$OLD_FAILING"; then
            echo "::error ::bfs test failed: $LINE. $LINE is passing on 'main'. Maybe you have to rebase?"
          fi
        done
    - name: Compare against main results
      shell: bash
      run: |
        mv dl/bfs-result.json latest-bfs-result.json
        python findutils/util/compare_bfs_result.py
